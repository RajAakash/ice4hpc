# -*- coding: utf-8 -*-
"""analysis_w_paper_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EZTRUg9Hg-sofoig8vkJjhp_09YQnn_G
"""
#!pip install optuna
#import index_maker
import util
import argparse
import yaml
import importlib
import optuna
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import tensorflow as tf
import random
from sklearn.ensemble import RandomForestRegressor
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Activation, Dropout, Flatten, Input, Dense, concatenate 
from sklearn.metrics import accuracy_score, precision_score, recall_score, r2_score, mean_squared_error, mean_absolute_percentage_error
from tensorflow.keras.models import Model, Sequential, load_model
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import preprocessing
import dataloader
from preprocessing import preprocessor
from dataloader import dataLoader
import sys
import os
import os.path
import csv
import copy
#import ensemRegressor
#import transfer_learning
#import optunatransformator1
#import stacked_model
#import k_regressor
import random_forrest
#import IPT
#import train_only
#import source_only
import mpi4py
#from transfer_learning import transfer_learning
#from stacked_model import stacked_model
#from k_regressor import k_regressor
from random_forrest import random_forrest
#from IPT import IPT
#from train_only import train_only
#from source_only import source_only
from mpi4py import MPI
from be_great import GReaT
#np.random.seed(1)  
#tf.random.set_seed(2)
#import optunannPOD
import re    
if __name__ == "__main__":
  comm = MPI.COMM_WORLD
  rank = comm.Get_rank()
  print(f"Rank is {rank}")
  #path_to_module = '/content/drive/MyDrive/'
  np.random.seed(1)  
  tf.random.set_seed(2)
  
  os.chdir("../../")
  parser = argparse.ArgumentParser()
  parser.add_argument('target_app', type=str,  help="name of the target domain")
  parser.add_argument('use_case', type=str,  help="which do want to fo from train_only, source_only, transfer_learning, random_forrest, k_regressor, IPT and stacked_model")
  parser.add_argument('yaml', type=str,  help="what will be the yaml file")
  args = parser.parse_args()
  with open(os.getcwd()+args.yaml, "r") as f:
    global_config= yaml.load(f, Loader=yaml.FullLoader)
  test_samples = global_config['test_samples']
  use_case_specific_config = global_config[args.use_case]
  #loader = dataLoader(os.getcwd()+global_config["src_path"], os.getcwd()+global_config["tar_path"])
  #loader.loadData()
  #src_x, src_y, tar_x, tar_y = loader.getXY("", "",global_config["target_label"])
  #src_x, src_y, tar_x, tar_y = loader.src_tx, loader.src_y, loader.tar_tx, loader.tar_y
  qrrploader = dataLoader(os.getcwd()+global_config["src_path1"] ,os.getcwd()+global_config["tar_path1"] )
  qrrploader.loadData()
  qrrp_src_x, qrrp_src_y, qrrp_tar_x, qrrp_tar_y = qrrploader.getXY("", "",["ruby_rp"])
  qrrp_p = preprocessor(qrrp_src_x, qrrp_src_y, qrrp_tar_x, qrrp_tar_y, 0)
  qrrp_p.setTargetColumn(["ruby_rp"])
  qrrp_src_tx, qrrp_src_ty = qrrploader.getSrcXY()
  qrrp_p.setSrcDFXY(qrrp_src_tx, qrrp_src_ty)
  qrrp_tar_tx, qrrp_tar_ty = qrrploader.getTarXY()
  qrrp_p.setTarDFXY(qrrp_tar_tx, qrrp_tar_ty)
  qrrp_p.preprocess()
  qrrp_tar_x_scaled, qrrp_tar_y_scaled = qrrp_p.getTargetScaled()
  qrrp_X_train, qrrp_y_train, qrrp_src_train, qrrp_src_y_train, qrrp_src_val, qrrp_src_y_val, qrrp_X_test, qrrp_y_test = qrrp_p.train_test_val( 0.05, 0.25, 42, 84) #100, 812


  try:
    with tf.device('/gpu:0'):
      counterLoader = dataLoader(os.getcwd()+global_config["src_counter"] ,os.getcwd()+global_config["tar_counter"] )
      counterLoader.lData()
      src_d, tar_d = counterLoader.gData()
      src_tx = src_d[list(set(src_d.columns)-set(global_config["targeted_counters"]))]
      src_ty = src_d[global_config["targeted_counters"]]
      tar_x = tar_d[list(set(src_d.columns)-set(global_config["targeted_counters"]))]
      print(f"len of src_tx {len(src_tx)}")
      ###data generation
      
      lm = GReaT(llm='distilgpt2', batch_size=32, epochs=100)
      print("going to generate data")
      #new_data = util.dataGen(lm, src_tx, src_ty, tar_x)


      list_of_dfs = []
      for column in src_ty.columns:
        tr1 = copy.deepcopy(src_tx)
        tr1[column] =  src_ty[column]
        lm.fit(tr1)
        temp = copy.deepcopy(tar_x)
        temp[column]= float("NAN") #np.nan
        imputed_data = lm.impute(temp, max_length=200)
        print(f"data imputation for {column} column done")
        list_of_dfs.append(imputed_data[[column]])
      i = 0
      for column in src_ty.columns:
        if i==0:
          tar_x = list_of_dfs[i]
        else:
          tar_x = pd.concat([tar_x, list_of_dfs[i]], axis=1)
        i = i + 1
      
      print("Data Generation finished")
      #print(f"src_d columns {src_d.columns}")
      #print(f"tar_x columns {tar_x.columns}")
      #counterLoader.setData(src_d, tar_x)

      """
      """
      print("***************************PreProcessing Done**********************************")
      ###data generation

      print("Data Generation finished")

      rcrploader = dataLoader(os.getcwd()+global_config["src_path2"],os.getcwd()+global_config["tar_path2"] )#("LDRD/Case-1-new_labels_2/q-c/Train/","LDRD/Case-1-new_labels_2/q-c/Test/")
      rcrploader.lData()
      temp_s, temp_t = rcrploader.gData()
      rcrploader.setData(temp_s, pd.concat([tar_x, temp_t[["corona_rp"]]], axis=1)) 
      #rcrploader.loadData()
      rcrp_src_x, rcrp_src_y, rcrp_tar_x, rcrp_tar_y = rcrploader.getXY("", "",["corona_rp"])
      rcrp_tar_x = np.reshape(rcrp_tar_x, (rcrp_tar_x.shape[0], rcrp_tar_x.shape[1]))
      rcrp_p = preprocessor(rcrp_src_x, rcrp_src_y, rcrp_tar_x, rcrp_tar_y, 0)
      rcrp_p.setTargetColumn(["corona_rp"])
      rcrp_src_tx, rcrp_src_ty = rcrploader.getSrcXY()
      rcrp_p.setSrcDFXY(rcrp_src_tx, rcrp_src_ty)
      rcrp_tar_tx, rcrp_tar_ty = rcrploader.getTarXY()
      rcrp_p.setTarDFXY(rcrp_tar_tx, rcrp_tar_ty)
      rcrp_p.preprocess()
      rcrp_tar_x_scaled, rcrp_tar_y_scaled = rcrp_p.getTargetScaled()
      rcrp_X_train, rcrp_y_train, rcrp_src_train, rcrp_src_y_train, rcrp_src_val, rcrp_src_y_val, rcrp_X_test, rcrp_y_test = rcrp_p.train_test_val( 0.05, 0.25, 42, 84)

      module_name, func_name = use_case_specific_config["module_name"], use_case_specific_config["class_name"]
      module = importlib.import_module(module_name)
      func = getattr(module, func_name)
      obj = func(use_case_specific_config["init_arg"])
      obj(os.getcwd()+args.yaml, args.target_app, qrrp_p, rcrp_p, qrrp_X_train, qrrp_y_train, qrrp_tar_x_scaled, qrrp_tar_y_scaled, rcrp_X_train, rcrp_y_train, rcrp_tar_x_scaled, rcrp_tar_y_scaled, rank)
  except RuntimeError as e:
    print(e)
