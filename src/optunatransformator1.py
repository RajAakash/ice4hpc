# -*- coding: utf-8 -*-
"""OptunaTransformator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZdWR2hrAvUYuLbB5dds7noqTEshBLsfS
"""

# -*- coding: utf-8 -*-
"""SubSpaceJSOptuna.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I9vXOXmCfmNA6dAk1ZJagTkIx6YJVkS7
"""

# -*- coding: utf-8 -*-
"""SubSpaceJS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13TKGc6sVjhS5Ok9MTliNmm8aGU8X4xX8
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.metrics import accuracy_score, precision_score, recall_score, r2_score, mean_squared_error
from sklearn.model_selection import train_test_split, KFold
from tensorflow.keras import layers, losses
from tensorflow.keras.models import Model

import random
import sys
import time
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow.keras.backend as keras_backend

from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import concatenate
from sklearn.feature_selection import mutual_info_regression
from sklearn.decomposition import PCA
from sklearn.preprocessing import normalize
from operator import add
from numpy import asarray
import math
import scipy
import seaborn as sns
#import networkx as nx
import numpy as np
import optuna as optuna
import json
from tabtransformertf.models.fttransformer import FTTransformerEncoder, FTTransformer
from tabtransformertf.utils.preprocessing import df_to_dataset


##################### Model Creation

class Transformator(tf.keras.Model):
  def __init__(self, dim, numOfLayersE, neuronsE, activationE):
    super(Transformator, self).__init__()
    self.array=[]
    self.nL = numOfLayersE
    self.neurons = neuronsE
    self.idim = dim
    self.actF = activationE
    initializer = tf.keras.initializers.RandomUniform(minval=0.3, maxval=0.6)
    #layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)
    self.hidden_layer = tf.keras.layers.Dense(
      units=neuronsE,
      activation=activationE
      #,kernel_initializer=initializer
    )
    for i in range(self.nL):
      self.array.append(Dense(neuronsE, activation=activationE))
    self.output_layer = tf.keras.layers.Dense(
      units= self.idim,
      activation=activationE
      #,kernel_initializer=initializer
    )
  def call(self, input_features):
    encoded = self.hidden_layer(input_features)
    for i in range(self.nL):
      encoded=self.array[i](encoded)
    #print("Activation ",activation)
    return self.output_layer(encoded)
  def get_config(self):
    return {"intermediate_dim": self.idim, "numOfLayers": self.nL,"neurons": self.neurons, "activation": self.actF }
  @classmethod
  def from_config(cls, config):
      return cls(**config)

def loss(input_translator, source_regressor, original_target, original_target_Labels):
  transformed = input_translator(original_target)
  print(f"transformed shape {transformed.shape}")
  predicted_target_labels = source_regressor(transformed)
  predicted_target_labels = tf.cast(predicted_target_labels, tf.float64)
  original_target_Labels = tf.cast(original_target_Labels, tf.float64)
  ls = tf.reduce_mean(tf.square(tf.subtract(predicted_target_labels, original_target_Labels)))
  return ls

def transformerLoss(input_translator, source_transformer, original_target, original_target_Labels, src_numerical_features, tar_numerical_features, LABEL):
  print(f"original target {original_target}")
  transformed = input_translator(original_target.values)
  print(f"transformed {transformed}")
  print(f"transformed shape {transformed.shape}")
  transformed = np.reshape(transformed, (len(original_target), len(src_numerical_features)) )
  transformed_df = pd.DataFrame(transformed, columns = src_numerical_features)
  print(f"transformed df {transformed_df}")
  original_df = pd.concat([transformed_df, original_target_Labels], axis=1)
  print(f"Original DF {original_df}")
  origin_dataset = df_to_dataset(original_df, LABEL, shuffle=True)  
  print(f"transformed shape {transformed.shape}")
  print(f"origin dataset {origin_dataset}")
  linear_test_preds = source_transformer.predict(origin_dataset)
  linear_rms = mean_squared_error(original_target_Labels, linear_test_preds['output'].ravel(), squared=False) 
  return linear_rms

def train( transformator, predictor, opt, original, original_labels):
  with tf.GradientTape() as tape, tf.GradientTape() as disc_tape:
    tape.watch(transformator.trainable_variables)
    ls = loss(transformator, predictor, original, original_labels)
    #ls = tf.cast(ls, tf.float64)
    #ls = tf.convert_to_tensor(ls, dtype=tf.float32)
    print("loss is ",ls)
    if (ls != 0):
      gradients = tape.gradient(ls, transformator.trainable_variables)
      gradient_variables = zip(gradients, transformator.trainable_variables)
      opt.apply_gradients(gradient_variables)
  return transformator


def trainwtransformer( transformator, transformer, opt, original, original_labels, src_numerical_features, tar_numerical_features, LABEL):
  with tf.GradientTape() as tape, tf.GradientTape() as disc_tape:
    tape.watch(transformator.trainable_variables)
    ls = transformerLoss(transformator, transformer, original, original_labels, src_numerical_features, tar_numerical_features, LABEL)
    #ls = tf.cast(ls, tf.float64)
    #ls = tf.convert_to_tensor(ls, dtype=tf.float32)
    print("loss is ",ls)
    if (ls != 0):
      gradients = tape.gradient(ls, transformator.trainable_variables)
      gradient_variables = zip(gradients, transformator.trainable_variables)
      opt.apply_gradients(gradient_variables)
  return transformator
#####################K fold Generation
def kfoldValidation(transformatorP, predictorP, optP, X, Y, fold):
  kfold = KFold(n_splits= fold, shuffle=False)
  mse_per_fold = []
  mae_per_fold = []
  mape_per_fold = []
  fold_no = 1
  #testmodel = transformatorP
  for train, test in kfold.split(X, Y):
    rowx = tf.gather(X, train)
    rowy = tf.gather(Y, train)
    #for i in range(epochS):
    #transformatorP = train(transformatorP, predictorP, optP, rowx, rowy)
    with tf.GradientTape() as tape, tf.GradientTape() as disc_tape:
      tape.watch(transformatorP.trainable_variables)
      ls = loss(transformatorP, predictorP, rowx, rowy)
      #ls = tf.cast(ls, tf.float64)
      #ls = tf.convert_to_tensor(ls, dtype=tf.float32)
      print("loss is ",ls)
      if (ls != 0):
        gradients = tape.gradient(ls, transformatorP.trainable_variables)
        gradient_variables = zip(gradients, transformatorP.trainable_variables)
        optP.apply_gradients(gradient_variables)

    tx = tf.gather(X, test)
    ty = tf.gather(Y, test)
    scores = loss(transformatorP, predictorP, tx, ty)
    #print(f'Score for fold {fold_no}: {testmodel.metrics_names[0]} of {scores[0]}; {testmodel.metrics_names[1]} of {scores[1]}; {testmodel.metrics_names[2]} of {scores[2]}; {testmodel.metrics_names[3]} of {scores[3]};')
    
    mse_per_fold.append(scores)
    #mae_per_fold.append(scores[2])
    #mape_per_fold.append(scores[3])
    fold_no += 1
  return transformatorP, mse_per_fold



class Objective(object):
  def __init__(self, regressor, targetP, target_labelsP, source_dim, epochs, cp_path, numFolds):
    # Hold this implementation specific arguments as the fields of the class.
    self.regressor = regressor
    self.org = targetP
    self.labels = target_labelsP
    self.dim = source_dim
    self.epochs = epochs
    self.savingPath = cp_path
    self.NumFolds = numFolds
    
  def __call__(self, trial):
    num_layers = trial.suggest_int('num_layers', 1, 10, 2)
    neuron = trial.suggest_categorical("neuron", [10, 50, 100, 200, 300, 500, 600, 800, 900, 1000] )
    batch_size = trial.suggest_int('batch_size', low = 50, high = 300, step=50)
    momentum = trial.suggest_float('Momentum', low=0.4, high=1.0, step=0.1)
    lr2 = trial.suggest_categorical("lr2", [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0])
    optimizer = keras.optimizers.Adam(learning_rate=lr2)

    transformator  = Transformator(dim = self.dim, numOfLayersE = num_layers, neuronsE = neuron, activationE = "relu")
    losses = []
    total_loss = 0
    for epoch in range(self.epochs):
      transformator, mse = kfoldValidation(transformator, self.regressor, optimizer, self.org, self.labels, self.NumFolds)
      ls = math.sqrt(np.mean(mse))
      losses.append(ls)
      trial.report(ls, epoch)
      if trial.should_prune():
          raise optuna.exceptions.TrialPruned()
      transformator.save_weights(self.savingPath+f"Trial-{trial.number}-model")
    return ls

def finder(regressor, targetP, target_labelsP, source_dim, epochs, checkpoint_path, num_of_trials, fold, stname, storageName):
  tf.debugging.set_log_device_placement(True)	
  with tf.device('/GPU:0'):
    loaded_study = optuna.load_study(study_name=stname, storage=storageName)
    obj = Objective(regressor, targetP, target_labelsP, source_dim, epochs, checkpoint_path, fold)
    #loaded_study.optimize(obj, n_trials= num_of_trials, callbacks=[obj.callback], gc_after_trial=True)
    loaded_study.optimize( obj, n_trials= num_of_trials, gc_after_trial=True)
    trial = loaded_study.best_trial   
  return trial
